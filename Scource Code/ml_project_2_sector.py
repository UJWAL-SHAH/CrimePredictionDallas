# -*- coding: utf-8 -*-
"""ML_Project_2_Sector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CtvW_S6Dqk6in-azS6hXJ0l9kTYiKJxZ

##Loading the Data
"""

! pip install xgboost
import os
from google.colab import drive
MOUNTPOINT = '/content/gdrive'
DATADIR = os.path.join(MOUNTPOINT, 'My Drive')
drive.mount(MOUNTPOINT)

path=os.path.join(DATADIR, 'Police_Incidents.csv')

import pandas as pd
df = pd.read_csv(path)

print(df.columns)

"""##With Sector"""

#column_names = ['NIBRS Group' , 'Division', 'Date of Report', 'Special Report (Pre-RMS)','Target Area Action Grids','Call (911) Problem','Weapon Used']
column_names = ['NIBRS Group' , 'Sector', 'Date of Report', 'Special Report (Pre-RMS)','Target Area Action Grids','Weapon Used','Victim Type','Victim Race',
'Victim Ethnicity','Victim Gender','Type  Location','Type of Property','Family Offense']

df1 = df[(df['City'] == 'DALLAS') | (df['City'] == 'Dallas')]
new_df = df1[column_names].copy()

new_df.head()

null_counts = new_df.isnull().sum()
null_percentages = null_counts / len(new_df) * 100

null_summary = pd.concat([null_counts, null_percentages], axis=1)
null_summary.columns = ['# of Nulls', '% of Nulls']

print(null_summary)

#Replace all Null value = 0 & non-Null vlaues = 1
non_null_values = new_df['Special Report (Pre-RMS)'].dropna().unique()
new_df['Special Report (Pre-RMS)'] = new_df['Special Report (Pre-RMS)'].fillna(0)
new_df['Special Report (Pre-RMS)'] = new_df['Special Report (Pre-RMS)'].replace(to_replace=non_null_values, value=1)

new_df = new_df.dropna(subset=['NIBRS Group','Sector'])

null_counts = new_df.isnull().sum()
null_percentages = null_counts / len(new_df) * 100

null_summary = pd.concat([null_counts, null_percentages], axis=1)
null_summary.columns = ['# of Nulls', '% of Nulls']

print(null_summary)

#Encoding the columns
new_df['Target Area Action Grids'].value_counts()

#Replace all Null value = 0 & non-Null vlaues = 1
non_null_values = new_df['Target Area Action Grids'].dropna().unique()
new_df['Target Area Action Grids'] = new_df['Target Area Action Grids'].fillna(0)
new_df['Target Area Action Grids'] = new_df['Target Area Action Grids'].replace(to_replace=non_null_values, value=1)

new_df['Target Area Action Grids'].value_counts()

new_df['NIBRS Group'] = new_df['NIBRS Group'].replace(['B', 'C'], 0)
new_df['NIBRS Group'] = new_df['NIBRS Group'].replace('A', 1)

new_df.head()

#Spliting date to year, month, day and time 
new_df['Date of Report'] = pd.to_datetime(new_df['Date of Report'])
new_df['Year'] = new_df['Date of Report'].dt.strftime('%Y')
new_df['Month'] = new_df['Date of Report'].dt.strftime('%m')
new_df['Day'] = new_df['Date of Report'].dt.strftime('%d')
new_df['Time'] = new_df['Date of Report'].dt.hour

new_df.head()

#creating and assigning watch2 values based on time of report 
new_df['watch2'] = 0  # Initialize all values to 0
new_df.loc[(new_df['Time'] >= 7) & (new_df['Time'] < 16), 'watch2'] = 2
new_df.loc[(new_df['Time'] >= 0) & (new_df['Time'] <7 ), 'watch2'] = 1
new_df.loc[(new_df['Time'] >=16) & (new_df['Time'] <=23 ), 'watch2'] = 3

#checking if watch2 has correct value

w2_df = new_df[new_df['watch2'] == 3] #change value of watch here
w2_df['Time'] = w2_df['Date of Report'].dt.hour
min_time = w2_df['Time'].min()
max_time = w2_df['Time'].max()

print('Minimum time:', min_time)
print('Maximum time:', max_time)

new_df.head()

new_df = new_df.drop('Date of Report', axis=1)
new_df.head()

new_df['Sector'].value_counts()

# Convert all values in "Sector" column to int
new_df['Sector'] = new_df['Sector'].astype(int)
new_df['Sector'].value_counts()

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
new_df["Sector"] = le.fit_transform(new_df["Sector"])
new_df.head()

new_df['Weapon Used'].value_counts()

new_df['Weapon Used'] = new_df['Weapon Used'].fillna('No Weapon')
new_df["Weapon Used"].isnull().sum()

new_df["Weapon Used"] = le.fit_transform(new_df["Weapon Used"])

#Checking Null Values
null_counts = new_df.isnull().sum()
null_percentages = null_counts / len(new_df) * 100

null_summary = pd.concat([null_counts, null_percentages], axis=1)
null_summary.columns = ['# of Nulls', '% of Nulls']

print(null_summary)

new_df['Family Offense'].value_counts()

#Replace all Null value = 0 & non-Null vlaues = 1
new_df['Family Offense'] = new_df['Family Offense'].fillna('True')
new_df['Family Offense'] = new_df['Family Offense'].astype(str)
new_df["Family Offense"] = le.fit_transform(new_df["Family Offense"])

new_df['Type of Property'].value_counts()

#Replace all Null value = 0 & non-Null vlaues = 1
new_df['Type of Property'] = new_df['Type of Property'].fillna('Other')
new_df['Type of Property'] = new_df['Type of Property'].astype(str)
new_df["Type of Property"] = le.fit_transform(new_df["Type of Property"])

#Replace all Null value = 0 & non-Null vlaues = 1
new_df['Family Offense'] = new_df['Family Offense'].fillna('True')
new_df['Family Offense'] = new_df['Family Offense'].astype(str)
new_df["Family Offense"] = le.fit_transform(new_df["Family Offense"])

new_df = new_df.dropna(subset=['Type  Location'])
new_df["Type  Location"] = le.fit_transform(new_df["Type  Location"])

new_df = new_df.dropna(subset=['Victim Type'])
new_df["Victim Type"] = le.fit_transform(new_df["Victim Type"])

new_df = new_df.dropna(subset=['Victim Race', 'Victim Ethnicity', 'Victim Gender'])

new_df["Victim Race"] = le.fit_transform(new_df["Victim Race"])
new_df["Victim Ethnicity"] = le.fit_transform(new_df["Victim Ethnicity"])
new_df["Victim Gender"] = le.fit_transform(new_df["Victim Gender"])

#Checking Null Values
null_counts = new_df.isnull().sum()
null_percentages = null_counts / len(new_df) * 100

null_summary = pd.concat([null_counts, null_percentages], axis=1)
null_summary.columns = ['# of Nulls', '% of Nulls']

print(null_summary)

new_df.head()

filtered_df = new_df.copy()

filtered_df['Sector'].value_counts()

filtered_df.head()

filtered_df = filtered_df.drop('Time', axis=1)
filtered_df.head()

filtered_df['Year'] = filtered_df['Year'].astype(int)
filtered_df['Month'] = filtered_df['Month'].astype(int)
filtered_df['Day'] = filtered_df['Day'].astype(int)

"""##Training the Model"""

from sklearn.model_selection import train_test_split

# Split the DataFrame into training and test sets
train_df, test_df = train_test_split(filtered_df, test_size=0.3)

# Split the test set into validation and test sets
val_df, test_df = train_test_split(test_df, test_size=0.5)

# Print the sizes of the resulting sets
print("Size of train set:", len(train_df))
print("Size of val set:", len(val_df))
print("Size of test set:", len(test_df))

# Remove the 'NIBRS Group' column from the training set
x_train = train_df.drop('NIBRS Group', axis=1)
y_train = train_df['NIBRS Group']

# Remove the 'NIBRS Group' column from the validation set
x_val = val_df.drop('NIBRS Group', axis=1)
y_val = val_df['NIBRS Group']

# Remove the 'NIBRS Group' column from the test set
x_test = test_df.drop('NIBRS Group', axis=1)
y_test = test_df['NIBRS Group']

# Reset the indices of the training set
x_train = x_train.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)

# Reset the indices of the validation set
x_val = x_val.reset_index(drop=True)
y_val = y_val.reset_index(drop=True)

# Reset the indices of the test set
x_test = x_test.reset_index(drop=True)
y_test = y_test.reset_index(drop=True)



"""##Bagging Model"""

from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import classification_report
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# Create a Decision Tree classifier as the base estimator
base_estimator = DecisionTreeClassifier()

# Create a BaggingClassifier object
bagging_model = BaggingClassifier(base_estimator=base_estimator, n_estimators=100)

# Train the model using x_train and y_train
bagging_model.fit(x_train, y_train)

# Once the model is trained, you can use it to make predictions on the testing data
y_pred_train = bagging_model.predict(x_train)
y_pred_val = bagging_model.predict(x_val)
y_pred_test = bagging_model.predict(x_test)


classification_report_train = classification_report(y_train, y_pred_train)
print("\nTraining Classification Report:\n",classification_report_train)

classification_report_val = classification_report(y_val, y_pred_val)
print("\nValidation Classification Report:\n",classification_report_val)

classification_report_test = classification_report(y_test, y_pred_test)
print("\nTesting Classification Report:\n",classification_report_test)

# generate confusion matrix
cm = confusion_matrix(y_val, y_pred_val)
sns.heatmap(cm, annot=True, fmt='d')
plt.show()

"""##Models to Test"""

import xgboost as xgb
from xgboost import XGBClassifier

import numpy as np
import matplotlib.pyplot as plt
from matplotlib.colors import ListedColormap
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.datasets import make_moons, make_circles, make_classification
from sklearn.neural_network import MLPClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis
from sklearn.inspection import DecisionBoundaryDisplay

names = [
    "Nearest Neighbors",
    "Decision Tree",
    "Random Forest",
    "Neural Net",
    "AdaBoost",
    "Gradient Boosting",
    "Naive Bayes",
    "QDA",
    "XGBoost"
]

classifiers = [
    KNeighborsClassifier(3),
    DecisionTreeClassifier(max_depth=5),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    MLPClassifier(alpha=1, max_iter=1000),
    AdaBoostClassifier(),
    GradientBoostingClassifier(),
    GaussianNB(),
    QuadraticDiscriminantAnalysis(),
    XGBClassifier(n_estimators=2, max_depth=2, learning_rate=0.1, objective='binary:logistic')
]


model_score ={}
for name, clf in zip(names, classifiers):

    clf = make_pipeline(StandardScaler(), clf)
    print("\nTraining Model: ",name)
    clf.fit(x_train, y_train)
    print("Models Training Accuaracy:",clf.score(x_train, y_train))
    score = clf.score(x_val, y_val)
    model_score[name] = score

for key, value in model_score.items():
    print(key, value)

"""##Other Models"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.pipeline import make_pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.ensemble import RandomForestClassifier


names = [
    "Decision Tree",
    "Random Forest",
    "AdaBoost",
    "Gradient Boosting",
    "XGBoost",
    "Bagging (Decision Tree)"
]

# Create a BaggingClassifier object
bagging_model = BaggingClassifier(base_estimator=base_estimator, n_estimators=100)
classifiers = [
    DecisionTreeClassifier(max_depth=5),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    AdaBoostClassifier(),
    GradientBoostingClassifier(),
    XGBClassifier(n_estimators=2, max_depth=2, learning_rate=0.1, objective='binary:logistic'),
    BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)
]

model_scores = {}
train_accuracies = []
val_accuracies = []

for name, clf in zip(names, classifiers):
    clf = make_pipeline(StandardScaler(), clf)
    print("\nTraining Model:", name)
    clf.fit(x_train, y_train)
    
    train_accuracy = clf.score(x_train, y_train)
    print("Model Training Accuracy:", train_accuracy)
    val_accuracy = clf.score(x_val, y_val)
    model_scores[name] = {'train_accuracy': train_accuracy, 'val_accuracy': val_accuracy}
    
    train_accuracies.append(train_accuracy)
    val_accuracies.append(val_accuracy)

# Plot the bar chart
plt.figure(figsize=(8, 6))
colors = plt.cm.Set1(np.linspace(0, 1, len(names)))
x = np.arange(len(names))
width = 0.35

plt.bar(x, train_accuracies, width, label='Train Accuracy', color=colors[0])
plt.bar(x + width, val_accuracies, width, label='Validation Accuracy', color=colors[1])

plt.xticks(x + width/2, names, rotation=45, ha="right")
plt.title("Model Performance Comparison")
plt.ylabel("Accuracy")
plt.ylim([0.0, 1.0])
plt.legend()

# Add labels on top of bars
for i, train_acc, val_acc in zip(x, train_accuracies, val_accuracies):
    plt.text(i, train_acc, f"{train_acc:.2f}", ha="center", va="bottom")
    plt.text(i + width, val_acc, f"{val_acc:.2f}", ha="center", va="bottom")

plt.tight_layout()
plt.show()

for key, value in model_scores.items():
    print(key, value)

import matplotlib.pyplot as plt
import numpy as np

train_error = [1 - accuracy for accuracy in train_accuracies]
val_error = [1 - accuracy for accuracy in val_accuracies]

def plot_error(model_list, train_error, val_error):
    n_models = len(model_list)
    index = np.arange(n_models)
    bar_width = 0.25

    plt.figure(figsize=(12, 8))
    plt.bar(index, train_error, bar_width, color='b', label='Training Error')
    plt.bar(index + bar_width, val_error, bar_width, color='g', label='Validation Error')

    plt.xlabel('Model')
    plt.ylabel('Error')
    plt.title('Training and Validation Error')
    plt.xticks(index + bar_width, model_list, rotation=45)
    # Move the legend outside and place it at the top
    plt.legend(loc='upper right', bbox_to_anchor=(1.12, 1))

    # Add labels on top of bars
    for i, (train_acc, val_acc) in enumerate(zip(train_error, val_error)):
        plt.text(i, train_acc, f"{train_acc:.2f}", ha="center", va="bottom")
        plt.text(i + bar_width, val_acc, f"{val_acc:.2f}", ha="center", va="bottom")

    plt.show()

plot_error(names, train_error, val_error)

"""##**VISUALIZATION**



"""

! pip install yellowbrick

# Importing ClassBalance visualizer
from yellowbrick.target import ClassBalance
X = filtered_df.drop('NIBRS Group', axis=1)
y = filtered_df['NIBRS Group']
classes = ["sever", "not-severe"]
# Creating the class imbalance plot
visualizer = ClassBalance(labels=classes)

visualizer.fit(y)

# Saving plot in PNG format
visualizer.show(outpath="Class_Imbalance_Plot.png")

import matplotlib.pyplot as plt

y = filtered_df['NIBRS Group']

# Get the value counts of y
value_counts = y.value_counts()

# Create the pie chart
plt.figure(figsize=(8, 8))
plt.pie(value_counts, labels=value_counts.index, autopct='%1.1f%%', startangle=90)

# Set the title of the pie chart
plt.title("Value Counts of Y")

# Show the plot
plt.axis('equal')
plt.legend(title="Classes", loc='best')

# Add percentages as text labels inside the pie chart
total = sum(value_counts)
for i, count in enumerate(value_counts):
    percentage = count / total * 100
    plt.text(0.5, 0.5, f"{percentage:.1f}%", horizontalalignment='center', verticalalignment='center')

plt.show()

from yellowbrick.model_selection import FeatureImportances
X = filtered_df.drop('NIBRS Group', axis=1)
y = filtered_df['NIBRS Group']
classes = ["Severe", "not-severe"]


# Importing RandomForestClassifier
from sklearn.ensemble import RandomForestClassifier

# Creating the feature importances plot
visualizer = FeatureImportances(RandomForestClassifier(max_depth=3),
                                relative=True)

visualizer.fit(X, y)

# Saving plot in PNG format
visualizer.show(outpath="Feature_Importances_Plot.png")

from yellowbrick.model_selection import FeatureImportances
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

X = filtered_df.drop('NIBRS Group', axis=1)
y = filtered_df['NIBRS Group']
classes = ["Severe", "not-severe"]

# Create a random forest classifier
model = RandomForestClassifier(max_depth=3)

# Fit the model
model.fit(X, y)

# Get feature importances
importances = model.feature_importances_

# Sort feature importances in descending order
indices = np.argsort(importances)[::-1]

# Set up the figure and axes
fig, ax = plt.subplots(figsize=(8, 6))

# Create a horizontal bar plot of the feature importances
ax.barh(range(X.shape[1]), importances[indices], align='center', color='skyblue')

# Set the y-axis ticks and labels
ax.set_yticks(range(X.shape[1]))
ax.set_yticklabels(X.columns[indices])

# Add text labels for feature importances
for i, importance in enumerate(importances[indices]):
    ax.text(importance, i, f"{importance:.2f}", ha='left', va='center')

# Set the x-axis label
ax.set_xlabel("Feature Importance")

# Set the title
ax.set_title("Feature Importances")

# Show the plot
plt.tight_layout()
plt.show()

"""**Finally by doing Feature Selction using Random Forest Classier & Gradietn Boosting the top 7 features out of 15 are listed below in chronological order fo their ranking** 



1.   Weapons Used
2.   Type of Property
3.  Type Location
4. Year
5. Victim Gender
6. Victim Ethinicity
7. Victim Race
8. Family Offense

Again using Prior Knowledge, we can remove the Column called as Year as it is tellling that a particular year had more Severe than non - severe Offense



"""

filtered_df.head()

# Save the DataFrame as a CSV file
x_train.to_csv('x_train.csv', index=False)

# Download the CSV file
from google.colab import files
files.download('x_train.csv')

import seaborn as sns

# Compute the correlation matrix using the selected columns
cols = ['Weapon Used','Type of Property','Type  Location','Victim Gender','Victim Ethnicity','Victim Race','Family Offense']

corr = x_train[cols].corr()

# Set up the Matplotlib figure and Seaborn heatmap
fig, ax = plt.subplots(figsize=(8,6))
sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax)

# Show the plot
plt.show()

"""**Now using the Top 5 Models & drawing the Precision Recall Graph**



1.   Decision Tree
2.   AdaBoost
3. Gradient Boosting
4. Random Forest
5. XGBoost
6. Bagging


"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

# Assuming you have 5 models named 'model1', 'model2', ..., 'model5'
models = [
    DecisionTreeClassifier(max_depth=5),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    AdaBoostClassifier(),
    GradientBoostingClassifier(),
    XGBClassifier(n_estimators=2, max_depth=2, learning_rate=0.1, objective='binary:logistic'),
    BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)
]

names = [
    "Decision Tree",
    "Random Forest",
    "AdaBoost",
    "Gradient Boosting",
    "XGBoost",
    "Bagging (Decision Tree)"
]
# Initialize empty lists to store accuracy, precision, and recall scores
accuracy_scores = []
precision_scores = []
recall_scores = []
f1_scores=[]

# Fit the models and store the scores
for model in models:
    model.fit(x_train, y_train)
    y_val_pred = model.predict(x_val)
    accuracy_scores.append(accuracy_score(y_val, y_val_pred))
    precision_scores.append(precision_score(y_val, y_val_pred))
    recall_scores.append(recall_score(y_val, y_val_pred))
    f1_scores.append(f1_score(y_val, y_val_pred))

# Set up the figure and axes
fig, ax = plt.subplots(figsize=(20, 6))

# Set up the bar chart data
bar_width = 0.15
bar_positions1 = np.arange(len(models))
bar_positions2 = bar_positions1 + bar_width
bar_positions3 = bar_positions1 + 2 * bar_width
bar_positions4 = bar_positions1 + 3 * bar_width

# Create the bar chart with lighter shades
ax.bar(bar_positions1, accuracy_scores, width=bar_width, label='Accuracy', edgecolor='black')
ax.bar(bar_positions2, precision_scores, width=bar_width, label='Precision', edgecolor='black')
ax.bar(bar_positions3, recall_scores, width=bar_width, label='Recall', edgecolor='black')
ax.bar(bar_positions4, f1_scores, width=bar_width, label='F1 Score', edgecolor='black')

# Set the axis labels and tick marks
ax.set_xticks(bar_positions2)
ax.set_xticklabels(names, rotation=45, ha='right')
ax.set_xlabel('Models')
ax.set_ylabel('Scores')
ax.set_title('Model Evaluation')

# Add values on top of bars
for i, acc, prec, rec, f1 in zip(bar_positions1, accuracy_scores, precision_scores, recall_scores, f1_scores):
    ax.text(i, acc, f"{acc:.2f}", ha='center', va='bottom')
    ax.text(i + bar_width, prec, f"{prec:.2f}", ha='center', va='bottom')
    ax.text(i + 2 * bar_width, rec, f"{rec:.2f}", ha='center', va='bottom')
    ax.text(i + 3 * bar_width, f1, f"{f1:.2f}", ha='center', va='bottom')

# Add a legend
ax.legend(loc='upper left', bbox_to_anchor=(0, 1), frameon=True)

# Show the plot
plt.show()

import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score

# Assuming you have 5 models named 'model1', 'model2', ..., 'model5'
models = [
    DecisionTreeClassifier(max_depth=5),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    AdaBoostClassifier(),
    GradientBoostingClassifier(),
    XGBClassifier(n_estimators=2, max_depth=2, learning_rate=0.1, objective='binary:logistic'),
    BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)
]

names = [
    "Decision Tree",
    "Random Forest",
    "AdaBoost",
    "Gradient Boosting",
    "XGBoost",
    "Bagging (Decision Tree)",
]

# Initialize empty lists to store accuracy, precision, and recall scores
accuracy_scores_train = []
precision_scores_train = []
recall_scores_train = []
f1_scores_train = []

accuracy_scores_val = []
precision_scores_val = []
recall_scores_val = []
f1_scores_val = []

accuracy_scores_test = []
precision_scores_test = []
recall_scores_test = []
f1_scores_test=[]


# Fit the models and store the scores
for i, model in enumerate(models):
    model.fit(x_train, y_train)
    
    # Train Set Scores
    print('\nModel =',model)
    y_train_pred = model.predict(x_train)
    accuracy_scores_train.append(accuracy_score(y_train, y_train_pred))
    precision_scores_train.append(precision_score(y_train, y_train_pred))
    recall_scores_train.append(recall_score(y_train, y_train_pred))
    print('\nTrain accuracy: ',accuracy_score(y_train, y_train_pred),'\nTrain Precision: ', precision_score(y_train, y_train_pred),'\nTrain Recall: ',recall_score(y_train, y_train_pred),'\nTrain F1 Score: ',f1_score(y_train, y_train_pred))
    
    # Validation Set Scores
    y_val_pred = model.predict(x_val)
    accuracy_scores_val.append(accuracy_score(y_val, y_val_pred))
    precision_scores_val.append(precision_score(y_val, y_val_pred))
    recall_scores_val.append(recall_score(y_val, y_val_pred))
    print('\nValidation accuracy: ',accuracy_score(y_val, y_val_pred),'\nValidation Precision: ', precision_score(y_val, y_val_pred),'\nValidation Recall: ',recall_score(y_val, y_val_pred),'\nVal F1 Score: ',f1_score(y_val, y_val_pred))
    
    y_test_pred = model.predict(x_test)
    accuracy_scores_test.append(accuracy_score(y_test, y_test_pred))
    precision_scores_test.append(precision_score(y_test, y_test_pred))
    recall_scores_test.append(recall_score(y_test, y_test_pred))
    print('\nTest accuracy: ',accuracy_score(y_test, y_test_pred),'\nTest Precision: ', precision_score(y_test, y_test_pred),'\nTest Recall: ',recall_score(y_test, y_test_pred),'\nTest F1 Score: ',f1_score(y_test, y_test_pred))


# Print the matrices

# Train Set
print("\nTrain Set:")
print("Train Accuracy:")
print(accuracy_scores_train)
print("Train Precision:")
print(precision_scores_train)
print("Train Recall:")
print(recall_scores_train)
print("Train F1 Score:")
print(f1_scores_train)

# Validation Set
print("\nValidation Set:")
print("Validation Accuracy:")
print(accuracy_scores_val)
print("Validation Precision:")
print(precision_scores_val)
print("Validation Recall:")
print(recall_scores_val)
print("Val F1 Score:")
print(f1_scores_val)

print("\nTest Set:")
print("Test Accuracy:")
print(accuracy_scores_test)
print("Test Precision:")
print(precision_scores_test)
print("Test Recall:")
print(recall_scores_test)
print("Test F1 Score:")
print(f1_scores_test)

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from itertools import cycle

# Assuming you have 5 models named 'model1', 'model2', ..., 'model5'
models = [
    DecisionTreeClassifier(max_depth=5),
    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),
    AdaBoostClassifier(),
    GradientBoostingClassifier(),
    XGBClassifier(n_estimators=2, max_depth=2, learning_rate=0.1, objective='binary:logistic'),
    BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=100)
]

model_names = [
    "Decision Tree",
    "Random Forest",
    "AdaBoost",
    "Gradient Boosting",
    "XGBoost",
    "Bagging (Decision Tree)"
]

# Set up the plot
plt.figure(figsize=(8, 6))

# Set up the colors for the lines
colors = cycle(['aqua', 'darkorange', 'cornflowerblue', 'green', 'purple'])

# Plot the ROC curve for each model
for i, model in enumerate(models):
    model.fit(x_train, y_train)
    y_score = model.predict_proba(x_val)
    fpr, tpr, _ = roc_curve(y_val, y_score[:, 1])
    roc_auc = auc(fpr, tpr)
    plt.plot(fpr, tpr, color=next(colors), lw=2, label=f'{model_names[i]} (AUC = {roc_auc:.2f})')

# Plot the random guessing line
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')

# Set the axis labels and title
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')

# Add the legend
plt.legend(loc='lower right')

# Show the plot
plt.show()